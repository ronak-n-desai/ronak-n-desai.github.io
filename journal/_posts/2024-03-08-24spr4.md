---
layout: post
title: Log-Scaling Correction, Grid Searches
use_math: true
category: journal
---

# Log-Scaling Correction

## Log-Scaling Correction Derivation
As I've mentioned [previously](https://ronak-n-desai.github.io/24spr3/), the log-scaling skews the predictions of a ML model. In fact, it always makes the ML model under-predict the true function. 
The log normal distribution (see [wikipedia](https://en.wikipedia.org/wiki/Log-normal_distribution) page) is what I am using to add noise to the output energies. The relevant formula is 

\begin{equation}
  \mu = \log\left(\frac{\mu_X^2}{\sqrt{\mu_X^2 + \sigma_X^2}}\right)
\end{equation}

Here, $\mu_X$ would be the value of the output energy. After log-scaling, the model will ideally learn the output energy to be $\mu$. When we exponentiate the model prediction, we will be left with $\exp(\mu) < \mu_X$. This is the origin of the under-prediction

The PDF of the log-normal distrubution is 

\begin{equation}
  f(x) = \frac{1}{x \sigma \sqrt{2 \pi}} \exp\left(- \frac{(\log(x) - \mu)^2}{2 \sigma^2} \right)
\end{equation}

where $\mu = \log\left(\frac{\mu_X}{\sqrt{1 + \alpha^2}} \right)$ is the mean of the logged distribution, $\sigma^2 = \log(1 + \alpha^2)$ is the variance of the logged distribution, and $\alpha = \sigma_X / \mu_X$ is the noise level of the original (log-normal) distribution. Additionally, $\mu_X$ and $\sigma_X$ are the mean and variance of the log-normal distribution. 

The expected value $E[x] = \mu_X$ can be confirmed by taking $\int_0^\infty x f(x)$ (I just used Mathematica). To get the expected value of the log of this distribution, we can take $\int Log(x) f(x) = \log\left(\frac{\mu_X}{\sqrt{1 + \alpha^2} } \right) = \mu$ which makes sense due to our definition of $\mu$. We can calculate the underprediction bias as a percentage as

\begin{equation}
\text{bias} = \frac{\mu_X - \mu^*}{\mu_X} \times 100 \% = \frac{\sqrt{1 + \alpha^2} - 1}{\sqrt{1 + \alpha^2}} \times 100 \% \label{eq:bias}
\end{equation}

where $\mu^* \equiv e^\mu$

This bias is something that is discussed online. A simple explanation can be given in this [Medium](https://roizner.medium.com/when-logarithmic-scale-in-prediction-models-causes-bias-d80d84e9e3d5) article. An academic article is given by [Miller 1984](https://www.jstor.org/stable/2683247?origin=crossref&seq=2)

## Techniques to Implement Prediction Correction
To fix this underprediction bias, we would want to multiply the predictions by a correction factor equal to $\mu_X / \mu^* = \sqrt{1 + \alpha^2}$. However, this comes with two assumptions. 

1. The noise in our experiment is distributed log-normally
2. We know the constant noise level $\alpha$ exactly.

This multiplicative factor of $\sqrt{1 + \alpha^2}$ should work for our synthetic data, but may be difficult to apply to real experimental data where the amount of noise and noise model may not be known exactly or hard to determine. However, the important thing is that in this process we are developing a correction factor that is equal to the ratio of two quantities: (1) the mean of the un-logged distribution, (2) the exponential of the mean of the logged distribution. We can determine (1) from the experimental dataset and (2) from the training predictions on the experimental dataset. I explored three ways to come up with an effective correction factor $C$. I will refer to the predictions as $y_P$ and the data as $y_D$. 

1. C = mean($y_D$) / mean($y_P$)
2. C = mean($y_D / y_P$)
3. Perform a linear least-squares fit $y_D = C y_P$ (setting the y-intercept to 0) to determine $C$

All three of these methods performed very similarly:

![image](https://github.com/ronak-n-desai/ronak-n-desai.github.io/assets/98538788/ceeef52a-53ff-476e-9d04-205886559d11)

The black dashed line shows the log-scaling bias from eq. \ref{eq:bias}. The gray dashed line shows the MAPE between the polynomial predictions and the exact energy (which is clearly affected by the log-scaling bias). 

In red, green, blue, we have the MAPE between the corrected polynomial predictions and exact energy from methods 1, 2, and 3 respectively. I plotted them with different line widths so that they are all visible together due to overlapping entirely. All of them perform pretty much the same and are able to have much lower MAPEs than the log-scaling bias curve. By the way, I developed the correction factor on the training set only, and used that correction factor to correct the testing set predictions for this plot.

To assess which ones if any are better, I looked at all 420 comparisons with the testing set (7 noise levels from 0 to 30, 3 energy outputs of max total average, 20 different training data points from 1000-20000) and counted which of the three methods had the lowest MAPE. Method 1 won 133 times, Method 2 won 206 times, Method 3 won 81 times. If I convert this to a percentage this is 

1. $31.7 \%$
2. $49.0 \%$
3. $19.3 \%$

So, it appears from this analysis that method 2 is a sensible choice to stick with. And, to me, it makes the most sense because it is averaging data point by data point this bias ratio. 

# Looking through data at WPAFB

## Diode Data (Main Pulse and Prepulse)
The diode data will be stored in files that look like the following: 

`DIODE-H7-00-2024-02-26_11h30m15s111ms.h5`

where `00` would correspond to the main pulse stored in `DAQ1` and `01` would correspond to the prepulse stored in `DAQ2`. 




