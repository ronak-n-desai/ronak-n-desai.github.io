---
layout: post
title: AFRL Data
use_math: true
category: journal
---

This post covers work from 05/20 - 05/31. 

# AFRL Data

## 05-10 Data Continued
I went ahead and fixed the shot number error from the `05-10` data by checking if more than a specified amount of shots seem to be dropped (I set it as 1024), then we should only add that previous shot number and not $2^{16}$. We can see this fixed in the following plot:

![image](https://github.com/ronak-n-desai/ronak-n-desai.github.io/assets/98538788/542345f1-4096-411e-a064-7f6a904de5b8)

If we zoom in, we can see that this is actually not fully continuous, many shots are being dropped

![image](https://github.com/ronak-n-desai/ronak-n-desai.github.io/assets/98538788/cdab82f5-6dce-4524-940a-d112ff4cee7e)

And in this plot, it looks like we get around 100 shots of data and then 500 shots of dropped data, but that may change throughout the run. I found that in this run, 556 was the maximum number of shots that got dropped in between two shot numbers, so my tolerance of 1024 is fine for now. I could increase it to be safe.

![image](https://github.com/ronak-n-desai/ronak-n-desai.github.io/assets/98538788/6df10cbf-e51c-461b-a24d-4e6be77c0f1f)

Here is a histogram that shows a count of shots throughout the in 25000 different bins. I've done this because there are approximately 250000 total shots in this run (Mightex shot count) and using 25000 bins, we would expect around 10 counts in each bin. 
Here, we see that this is true, but we we also see all the gaps in the data as well. While doing this experimental run, we did observe turning off the data saving made the shots not drop. Unfortunately, I cannot show that here because that data wasn't saved. 

Here is the summary plot I made last time, without the shot number error: 

![image](https://github.com/ronak-n-desai/ronak-n-desai.github.io/assets/98538788/ea01ea41-2f0d-416b-8dc3-367e9b52f598)

## Zooming in on Optimization

## Some Improvements on DataManager

### Dropped Shots Error Check
From what I realized in the data from 05-10, shots seem to frequently drop. However, there doesn't seem to be a stretch of time where about more than 600 shots drop. Just to be safe, I added a default shot dropping tolerance of 2048. This means that if more than 2048 shots are dropped, we detect this as an error and account for this. I've implemented this as a new argument to the datamanager constructor `dropped_shots_tol=2**11`. I decided to add this to the constructor, because I noticed the same thing happened with the 05-13 data, so it is a good thing that we can adjust it.

### Maximum and Minimum MP and PP Angles
I used to just take the maximum and minimum mp and pp angles in the `df_wp` to determine the angle boundaries. Now, take the 99th and 1st percentiles for the max and min angles. This may help if there is an outlier somewhere. Additionally, if there's still an error, I give the option to manually set the angles in the `DataManager` constructor as follows: `angle_max=(None, None)`, `angle_min=(None,None)`. When the values are `None`, I resort to the 99th and 1st percentile calculation, but if numbers are passed in, that percentile calculation is skipped and the manually supplied values are used.

### Electron Count
I lowered the tolerance from 100,000 to 75,000 for the min electron count so that we don't shave off as many data points.

### Waveplate Regression
I changed the prepulse waveplate regression to just directly predict the angle instead of the cosine squared of the angle. I experimented with using a 9th degree polynomial, but it gave some overflow error when trying to convert a voltage back to an angle. As a result, I'll just stick with the 3rd degree polynomial.



# Overview of some papers I've read this week

## PROBIES

Nathaniel told me that we're planning to change out the proton spectrometer and we might get a new one with the [PROBIES](https://pubs.aip.org/aip/rsi/article/94/2/023507/2869320/A-flexible-proton-beam-imaging-energy-spectrometer) diagnostic (Proton Beam Imaging Energy Spectrometer). Some of the drawbacks of conventional proton diagnostics (e.g. RCFs) include the following:
- Need many RCF stacks
  + RCF stacks are costly and time-consuming. 
- Alternatively, in a CCD spectrometer like ours, need a small solid angle beam to travel in straight line
  + Only have access to a small portion of the proton beam -- limited counts
PROBIES has been deployed at Omega EP and NIF-ARC. It essentially takes what RCF is doing in terms of stacks and instead turns a layer of 9 stacks into pixel subdivided into 9 sub elements (of each different thickness and thus filtering for different energies), repeated throughout one big stack. Here is a figure from the paper: 

![image](https://github.com/ronak-n-desai/ronak-n-desai.github.io/assets/98538788/8d0fbcd6-a2e9-45d8-aeaa-8304b06e4a92)

In this way, we only need one layer and can also capture a spatial dependence of the energy measurements. One interesting thing about this paper is that it also uses a Machine Learning analysis to explore the effectiveness of PROBIES that uses experimental data augmented with synthetic data with CNNs. 

## High-Energy Proton Beams

[This](https://www.nature.com/articles/s41567-024-02505-0) paper by Ziegler achieves record high 150MeV protons from TNSA. This was conducted at the Draco PW laser at HZDR. They use a 30fs laser, 250nm plastic foil target, 

The paper has **cascaded acceleration** in its name because there are multiple different acceleration mechanicsms present that contribute to the high energy beams. This figure

![image](https://github.com/ronak-n-desai/ronak-n-desai.github.io/assets/98538788/92c47de3-c6fe-446e-931d-9f060312cc49)

shows the different mechanisms that are present at different angles and proton energies of the emitted proton spectrum. FSA refers to radiation pressure resulting in front surface acceleration. Prompt refers to the acceleration caused by the first electron bunches forming in the sheath field.  Thermal refers to heating via absorption in the sheath field. Finally, Coulomb Repulsion (CR) refers to, at a later time, the protons themselves repelling each other to add more energy. These would repel in the transverse direction, so this would only be seen at a higher angular divergence. These different mechanisms can be seen in this plot showing the electric field as a function of the laser propagation direction and time. 

![image](https://github.com/ronak-n-desai/ronak-n-desai.github.io/assets/98538788/c9c0e513-b882-4461-bdb3-ee7a35b3d3b7)


## Electron Temperature Scaling

The paper from [Rusby](https://pubs.aip.org/aip/pop/article/31/4/040503/3284907/Review-and-meta-analysis-of-electron-temperatures) at the LLNL group does a review on the different electron temperature scalings that are out there. 

The Wilks (Ponderomotive) Scaling is given by 

\begin{equation}
T_p = m_e c^2 (\sqrt{1 + a_0^2/2} - 1)
\end{equation}

The Pukhov Scaling is given by 

\begin{equation}
  T_\text{pukhov} = 1.5 \text{MeV} (I/I_{18})^{0.5}
\end{equation}

Two newer scalings are given by Shen and Miller

\begin{equation}
  T_\text{shen} = 0.8 (I_{18})^{0.5} (\tau_{i,ps})^{0.65}
\end{equation}

where $\tau_{i,ps} = \tau + l_{ch}/c$ where $l_{ch}$ is the length of the channel and $\tau$ is the usual pulse duration. This uses a 0.7 ps pulse in the paper and the channel length is not clear, so this may not be useful.

\begin{equation}
  T_\text{miller} = (\frac{1}{E_D} + \frac{1}{L T_p})^{-1}
\end{equation}

where $E_D \approx \frac{m_e c^2 a_0}{2 \sqrt{\pi}} \sqrt{\frac{\tau}{T_0}}$ where $\tau$ is the pulse duration and $T_0$ is the laser period (time between start of one pulse and start of next, because there is a gap in time between the pulses and they aren't all back to back). $L = \text{MAX}(L_S/\lambda, 1)$ where $L_S$ is the scale length of the plasma is a modification introduced to make the temperature depend on both the laser duration $\tau$ and the scale length $L_S$. In our case, I believe the scale length would be $c_s t$ from reading the miller paper. Notably, all these scalings have scalings with $I^{0.5}$ (or alternatively $a_0$). The Beg Scaling is 

\begin{equation}
  T_\text{beg} = 0.469 a_0^{2/3} m_e c^2 = 215 (I_{18} \lambda_{\mu m}^2)^{1/3}
\end{equation}

which is what we've been using to get a more pronounced dip in the Fuchs Function, but wasn't focused on in this paper. 

Then, they go on to create an empirical scaling based on simulations as 

\begin{equation}
  T_\text{sim} \approx 1.57 T_p (\tau_{ps} L_{\mu m})^{0.34}
\end{equation}

which can easily be compared to the Wilks Scaling. $L_{\mu m}$ is the scale length of the plasma. We can try to implement some of these scalings in our synthetic model.








